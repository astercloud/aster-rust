//! æ‘˜è¦ç”Ÿæˆæ¨¡å—
//!
//! ä¸º SubAgent ç»“æœç”Ÿæˆç²¾ç‚¼æ‘˜è¦ï¼Œå‡å°‘è¿”å›ç»™çˆ¶ Agent çš„ token æ•°

use super::types::{SubAgentResult, TokenUsage};

/// æ‘˜è¦ç”Ÿæˆå™¨
pub struct SummaryGenerator {
    /// æœ€å¤§æ‘˜è¦ token æ•°
    max_tokens: usize,
}

impl Default for SummaryGenerator {
    fn default() -> Self {
        Self::new(2000)
    }
}

impl SummaryGenerator {
    /// åˆ›å»ºæ‘˜è¦ç”Ÿæˆå™¨
    pub fn new(max_tokens: usize) -> Self {
        Self { max_tokens }
    }

    /// ä¸ºå•ä¸ªç»“æœç”Ÿæˆæ‘˜è¦
    pub fn summarize_result(&self, result: &SubAgentResult) -> String {
        if let Some(summary) = &result.summary {
            return self.truncate_to_tokens(summary, self.max_tokens);
        }

        if let Some(output) = &result.output {
            return self.create_summary_from_output(output, result);
        }

        if let Some(error) = &result.error {
            return format!("ä»»åŠ¡ {} å¤±è´¥: {}", result.task_id, error);
        }

        format!("ä»»åŠ¡ {} å®Œæˆï¼Œæ— è¾“å‡º", result.task_id)
    }

    /// åˆå¹¶å¤šä¸ªç»“æœçš„æ‘˜è¦
    pub fn merge_summaries(&self, results: &[SubAgentResult]) -> String {
        let mut sections = Vec::new();
        let mut total_tokens = 0;
        let tokens_per_result = self.max_tokens / results.len().max(1);

        for result in results {
            let summary = self.summarize_result(result);
            let truncated = self.truncate_to_tokens(&summary, tokens_per_result);

            let section = if result.success {
                format!("âœ… {}: {}", result.task_id, truncated)
            } else {
                format!("âŒ {}: {}", result.task_id, truncated)
            };

            total_tokens += self.estimate_tokens(&section);
            if total_tokens > self.max_tokens {
                sections.push("... (æ›´å¤šç»“æœå·²çœç•¥)".to_string());
                break;
            }

            sections.push(section);
        }

        // æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        let success_count = results.iter().filter(|r| r.success).count();
        let fail_count = results.len() - success_count;
        let total_duration: u64 = results.iter().map(|r| r.duration.as_millis() as u64).sum();

        let stats = format!(
            "\n---\nğŸ“Š ç»Ÿè®¡: {} æˆåŠŸ, {} å¤±è´¥, æ€»è€—æ—¶ {:.2}s",
            success_count,
            fail_count,
            total_duration as f64 / 1000.0
        );

        format!("{}\n{}", sections.join("\n\n"), stats)
    }

    /// ä»è¾“å‡ºåˆ›å»ºæ‘˜è¦
    fn create_summary_from_output(&self, output: &str, result: &SubAgentResult) -> String {
        let status = if result.success { "æˆåŠŸ" } else { "å¤±è´¥" };
        let duration = result.duration.as_secs_f64();

        // æå–å…³é”®ä¿¡æ¯
        let key_points = self.extract_key_points(output);

        let mut summary = format!(
            "ä»»åŠ¡ {} {} (è€—æ—¶ {:.2}s)\n",
            result.task_id, status, duration
        );

        if !key_points.is_empty() {
            summary.push_str("å…³é”®å‘ç°:\n");
            for point in key_points.iter().take(5) {
                summary.push_str(&format!("- {}\n", point));
            }
        }

        self.truncate_to_tokens(&summary, self.max_tokens)
    }

    /// æå–å…³é”®ç‚¹
    fn extract_key_points(&self, text: &str) -> Vec<String> {
        let mut points = Vec::new();

        // æå–ä»¥ç‰¹å®šæ ‡è®°å¼€å¤´çš„è¡Œ
        for line in text.lines() {
            let trimmed = line.trim();
            if trimmed.starts_with("- ")
                || trimmed.starts_with("* ")
                || trimmed.starts_with("â€¢ ")
                || trimmed.starts_with("âœ“ ")
                || trimmed.starts_with("âœ… ")
            {
                points.push(trimmed.chars().skip(2).collect());
            } else if trimmed.starts_with("1.")
                || trimmed.starts_with("2.")
                || trimmed.starts_with("3.")
            {
                if let Some(content) = trimmed.split_once('.') {
                    points.push(content.1.trim().to_string());
                }
            }
        }

        // å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ—è¡¨é¡¹ï¼Œæå–é¦–å°¾æ®µè½
        if points.is_empty() {
            let paragraphs: Vec<&str> = text
                .split("\n\n")
                .filter(|p| !p.trim().is_empty())
                .collect();

            if let Some(first) = paragraphs.first() {
                points.push(self.truncate_text(first, 200));
            }
            if paragraphs.len() > 1 {
                if let Some(last) = paragraphs.last() {
                    points.push(self.truncate_text(last, 200));
                }
            }
        }

        points
    }

    /// æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šå­—ç¬¦æ•°
    fn truncate_text(&self, text: &str, max_chars: usize) -> String {
        if text.chars().count() <= max_chars {
            text.to_string()
        } else {
            let truncated: String = text.chars().take(max_chars - 3).collect();
            format!("{}...", truncated)
        }
    }

    /// æˆªæ–­åˆ°æŒ‡å®š token æ•°
    fn truncate_to_tokens(&self, text: &str, max_tokens: usize) -> String {
        let estimated = self.estimate_tokens(text);
        if estimated <= max_tokens {
            return text.to_string();
        }

        // ç²—ç•¥ä¼°ç®—ï¼š4 å­—ç¬¦ â‰ˆ 1 token
        let max_chars = max_tokens * 4;
        self.truncate_text(text, max_chars)
    }

    /// ä¼°ç®— token æ•°ï¼ˆç²—ç•¥ï¼‰
    fn estimate_tokens(&self, text: &str) -> usize {
        // ç®€å•ä¼°ç®—ï¼š4 å­—ç¬¦ â‰ˆ 1 token
        text.len() / 4
    }
}

/// è®¡ç®—æ€» token ä½¿ç”¨é‡
pub fn calculate_total_token_usage(results: &[SubAgentResult]) -> TokenUsage {
    let mut total = TokenUsage::default();

    for result in results {
        if let Some(usage) = &result.token_usage {
            total.input_tokens += usage.input_tokens;
            total.output_tokens += usage.output_tokens;
            total.total_tokens += usage.total_tokens;
        }
    }

    total
}

#[cfg(test)]
mod tests {
    use super::*;
    use chrono::Utc;
    use std::collections::HashMap;
    use std::time::Duration;

    fn create_test_result(task_id: &str, success: bool, output: Option<&str>) -> SubAgentResult {
        SubAgentResult {
            task_id: task_id.to_string(),
            success,
            output: output.map(|s| s.to_string()),
            summary: None,
            error: if success {
                None
            } else {
                Some("æµ‹è¯•é”™è¯¯".to_string())
            },
            duration: Duration::from_secs(1),
            retries: 0,
            started_at: Utc::now(),
            completed_at: Utc::now(),
            token_usage: Some(TokenUsage {
                input_tokens: 100,
                output_tokens: 50,
                total_tokens: 150,
            }),
            metadata: HashMap::new(),
        }
    }

    #[test]
    fn test_summarize_success_result() {
        let generator = SummaryGenerator::new(1000);
        let result = create_test_result("task-1", true, Some("ä»»åŠ¡å®Œæˆ"));

        let summary = generator.summarize_result(&result);
        assert!(summary.contains("task-1"));
        assert!(summary.contains("æˆåŠŸ"));
    }

    #[test]
    fn test_summarize_failed_result() {
        let generator = SummaryGenerator::new(1000);
        let result = create_test_result("task-1", false, None);

        let summary = generator.summarize_result(&result);
        assert!(summary.contains("task-1"));
        assert!(summary.contains("å¤±è´¥"));
    }

    #[test]
    fn test_merge_summaries() {
        let generator = SummaryGenerator::new(2000);
        let results = vec![
            create_test_result("task-1", true, Some("ç»“æœ1")),
            create_test_result("task-2", true, Some("ç»“æœ2")),
            create_test_result("task-3", false, None),
        ];

        let merged = generator.merge_summaries(&results);
        assert!(merged.contains("task-1"));
        assert!(merged.contains("task-2"));
        assert!(merged.contains("task-3"));
        assert!(merged.contains("2 æˆåŠŸ"));
        assert!(merged.contains("1 å¤±è´¥"));
    }

    #[test]
    fn test_extract_key_points() {
        let generator = SummaryGenerator::new(1000);
        let text = "æ¦‚è¿°\n- å‘ç°1\n- å‘ç°2\n* å‘ç°3";

        let points = generator.extract_key_points(text);
        assert_eq!(points.len(), 3);
        assert!(points.contains(&"å‘ç°1".to_string()));
    }

    #[test]
    fn test_calculate_total_token_usage() {
        let results = vec![
            create_test_result("task-1", true, None),
            create_test_result("task-2", true, None),
        ];

        let total = calculate_total_token_usage(&results);
        assert_eq!(total.input_tokens, 200);
        assert_eq!(total.output_tokens, 100);
        assert_eq!(total.total_tokens, 300);
    }
}
