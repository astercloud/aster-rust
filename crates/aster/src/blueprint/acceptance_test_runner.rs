//! éªŒæ”¶æµ‹è¯•è¿è¡Œå™¨
//!
//! ç”¨äºåœ¨ä»£ç ä¿®æ”¹åè‡ªåŠ¨è¿è¡Œç›¸å…³çš„éªŒæ”¶æµ‹è¯•ã€‚
//! è¿™æ˜¯éªŒè¯å±‚çš„æ ¸å¿ƒç»„ä»¶ï¼Œé›†æˆåˆ° PostToolUse hook ä¸­ã€‚
//!
//! ç‰¹ç‚¹ï¼š
//! 1. æ ¹æ®ä¿®æ”¹çš„æ–‡ä»¶æ‰¾åˆ°ç›¸å…³çš„éªŒæ”¶æµ‹è¯•
//! 2. å¼‚æ­¥æ‰§è¡Œï¼Œä¸é˜»å¡å¯¹è¯
//! 3. è®°å½•æµ‹è¯•ç»“æœåˆ°ä»»åŠ¡æ ‘
//! 4. æ”¯æŒå¤šç§æµ‹è¯•æ¡†æ¶

use std::path::{Path, PathBuf};
use std::process::Stdio;
use std::sync::Arc;
use std::time::Instant;
use tokio::process::Command;
use tokio::sync::RwLock;

use super::blueprint_manager::BlueprintManager;
use super::task_tree_manager::TaskTreeManager;
use super::types::{AcceptanceTest, TaskNode};

// ============================================================================
// ç±»å‹å®šä¹‰
// ============================================================================

/// æµ‹è¯•è¿è¡Œç»“æœ
#[derive(Debug, Clone)]
pub struct AcceptanceTestRunResult {
    /// æµ‹è¯• ID
    pub test_id: String,
    /// æµ‹è¯•åç§°
    pub test_name: String,
    /// æ˜¯å¦é€šè¿‡
    pub passed: bool,
    /// è¾“å‡ºå†…å®¹
    pub output: String,
    /// æ‰§è¡Œæ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
    pub duration: u64,
    /// é”™è¯¯ä¿¡æ¯
    pub error_message: Option<String>,
}

/// è¿è¡Œå™¨é…ç½®
#[derive(Debug, Clone)]
pub struct AcceptanceTestRunnerConfig {
    /// é¡¹ç›®æ ¹ç›®å½•
    pub project_root: PathBuf,
    /// æµ‹è¯•è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    pub test_timeout: u64,
    /// æ˜¯å¦å¯ç”¨è°ƒè¯•æ—¥å¿—
    pub debug: bool,
    /// å¹¶è¡Œè¿è¡Œæµ‹è¯•æ•°é‡
    pub parallel_count: usize,
}

impl Default for AcceptanceTestRunnerConfig {
    fn default() -> Self {
        Self {
            project_root: std::env::current_dir().unwrap_or_default(),
            test_timeout: 60000,
            debug: false,
            parallel_count: 1,
        }
    }
}

// ============================================================================
// éªŒæ”¶æµ‹è¯•è¿è¡Œå™¨
// ============================================================================

/// éªŒæ”¶æµ‹è¯•è¿è¡Œå™¨
pub struct AcceptanceTestRunner {
    config: AcceptanceTestRunnerConfig,
    task_tree_manager: Arc<RwLock<TaskTreeManager>>,
    blueprint_manager: Arc<RwLock<BlueprintManager>>,
}

impl AcceptanceTestRunner {
    /// åˆ›å»ºæ–°çš„è¿è¡Œå™¨
    pub fn new(
        config: AcceptanceTestRunnerConfig,
        task_tree_manager: Arc<RwLock<TaskTreeManager>>,
        blueprint_manager: Arc<RwLock<BlueprintManager>>,
    ) -> Self {
        Self {
            config,
            task_tree_manager,
            blueprint_manager,
        }
    }

    /// è¿è¡Œä¸ä¿®æ”¹æ–‡ä»¶ç›¸å…³çš„éªŒæ”¶æµ‹è¯•
    pub async fn run_tests_for_file(&self, file_path: &str) -> Vec<AcceptanceTestRunResult> {
        let tree_manager = self.task_tree_manager.read().await;

        // è·å–å½“å‰ä»»åŠ¡æ ‘
        let tree = match tree_manager.get_current_task_tree().await {
            Some(t) => t,
            None => {
                self.log("[AcceptanceTestRunner] æ²¡æœ‰æ´»è·ƒçš„ä»»åŠ¡æ ‘");
                return vec![];
            }
        };

        // æ‰¾åˆ°ç›¸å…³çš„éªŒæ”¶æµ‹è¯•
        let relevant_tests = self.find_relevant_tests(file_path, &tree.root).await;
        if relevant_tests.is_empty() {
            self.log(&format!(
                "[AcceptanceTestRunner] æ²¡æœ‰æ‰¾åˆ°ä¸ {} ç›¸å…³çš„éªŒæ”¶æµ‹è¯•",
                file_path
            ));
            return vec![];
        }

        self.log(&format!(
            "[AcceptanceTestRunner] æ‰¾åˆ° {} ä¸ªç›¸å…³æµ‹è¯•",
            relevant_tests.len()
        ));

        let mut results = Vec::new();

        // ä¸²è¡Œæˆ–å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
        if self.config.parallel_count > 1 {
            // å¹¶è¡Œæ‰§è¡Œ
            let batches = self.create_batches(&relevant_tests, self.config.parallel_count);
            for batch in batches {
                let mut handles = Vec::new();
                for test in batch {
                    let test_clone = test.clone();
                    let config = self.config.clone();
                    handles.push(tokio::spawn(async move {
                        Self::run_single_test_static(&config, &test_clone).await
                    }));
                }
                for handle in handles {
                    if let Ok(result) = handle.await {
                        results.push(result);
                    }
                }
            }
        } else {
            // ä¸²è¡Œæ‰§è¡Œ
            for test in &relevant_tests {
                let result = self.run_single_test(test).await;
                results.push(result);
            }
        }

        // è®°å½•æµ‹è¯•ç»“æœåˆ°ä»»åŠ¡æ ‘
        drop(tree_manager);
        self.record_results(&tree.id, &results).await;

        // è¾“å‡ºæ±‡æ€»
        self.print_summary(&results);

        results
    }

    /// è¿è¡ŒæŒ‡å®šçš„éªŒæ”¶æµ‹è¯•
    pub async fn run_acceptance_test(&self, test: &AcceptanceTest) -> AcceptanceTestRunResult {
        self.run_single_test(test).await
    }

    /// è¿è¡Œå•ä¸ªæµ‹è¯•
    async fn run_single_test(&self, test: &AcceptanceTest) -> AcceptanceTestRunResult {
        Self::run_single_test_static(&self.config, test).await
    }

    /// é™æ€æ–¹æ³•ï¼šè¿è¡Œå•ä¸ªæµ‹è¯•ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰
    async fn run_single_test_static(
        config: &AcceptanceTestRunnerConfig,
        test: &AcceptanceTest,
    ) -> AcceptanceTestRunResult {
        let start_time = Instant::now();

        if config.debug {
            println!("[AcceptanceTestRunner] è¿è¡Œæµ‹è¯•: {}", test.name);
        }

        match Self::execute_test_command(config, &test.test_command, Some(&test.test_file_path))
            .await
        {
            Ok(output) => {
                let duration = start_time.elapsed().as_millis() as u64;
                let passed = Self::parse_test_success(&output);

                let result = AcceptanceTestRunResult {
                    test_id: test.id.clone(),
                    test_name: test.name.clone(),
                    passed,
                    output: output.clone(),
                    duration,
                    error_message: if passed {
                        None
                    } else {
                        Some(Self::extract_error_message(&output))
                    },
                };

                if passed {
                    println!("âœ… éªŒæ”¶æµ‹è¯•é€šè¿‡: {} ({}ms)", test.name, duration);
                } else {
                    eprintln!("âŒ éªŒæ”¶æµ‹è¯•å¤±è´¥: {}", test.name);
                    if let Some(ref err) = result.error_message {
                        if let Some(first_line) = err.lines().next() {
                            eprintln!("   é”™è¯¯: {}", first_line);
                        }
                    }
                }

                result
            }
            Err(e) => {
                let duration = start_time.elapsed().as_millis() as u64;
                eprintln!("âŒ éªŒæ”¶æµ‹è¯•æ‰§è¡Œå¤±è´¥: {}", test.name);
                eprintln!("   {}", e);

                AcceptanceTestRunResult {
                    test_id: test.id.clone(),
                    test_name: test.name.clone(),
                    passed: false,
                    output: String::new(),
                    duration,
                    error_message: Some(e),
                }
            }
        }
    }

    /// æ‰¾åˆ°ä¸ä¿®æ”¹æ–‡ä»¶ç›¸å…³çš„éªŒæ”¶æµ‹è¯•
    async fn find_relevant_tests(
        &self,
        file_path: &str,
        root_task: &TaskNode,
    ) -> Vec<AcceptanceTest> {
        let mut tests = Vec::new();
        let normalized_path = Path::new(file_path).to_string_lossy().to_lowercase();

        self.traverse_for_tests(root_task, &normalized_path, &mut tests)
            .await;
        tests
    }

    /// é€’å½’éå†ä»»åŠ¡æ ‘æŸ¥æ‰¾ç›¸å…³æµ‹è¯•
    async fn traverse_for_tests(
        &self,
        task: &TaskNode,
        normalized_file_path: &str,
        tests: &mut Vec<AcceptanceTest>,
    ) {
        for test in &task.acceptance_tests {
            if self
                .is_test_relevant(test, normalized_file_path, task)
                .await
            {
                tests.push(test.clone());
            }
        }

        for child in &task.children {
            Box::pin(self.traverse_for_tests(child, normalized_file_path, tests)).await;
        }
    }

    /// åˆ¤æ–­æµ‹è¯•æ˜¯å¦ä¸ä¿®æ”¹æ–‡ä»¶ç›¸å…³
    async fn is_test_relevant(
        &self,
        _test: &AcceptanceTest,
        normalized_file_path: &str,
        task: &TaskNode,
    ) -> bool {
        // 1. æ£€æŸ¥ä»»åŠ¡çš„ä»£ç äº§å‡ºç‰©æ˜¯å¦åŒ…å«è¯¥æ–‡ä»¶
        for artifact in &task.code_artifacts {
            if let Some(ref artifact_path) = artifact.file_path {
                let artifact_normalized = artifact_path.to_lowercase();
                if normalized_file_path.contains(&artifact_normalized)
                    || artifact_normalized.contains(normalized_file_path)
                {
                    return true;
                }
            }
        }

        // 2. æ£€æŸ¥ä»»åŠ¡æ‰€å±æ¨¡å—æ˜¯å¦åŒ…å«è¯¥æ–‡ä»¶
        if let Some(ref module_id) = task.blueprint_module_id {
            let bp_manager = self.blueprint_manager.read().await;
            if let Some(blueprint) = bp_manager.get_current_blueprint().await {
                if let Some(module) = blueprint.modules.iter().find(|m| &m.id == module_id) {
                    let default_path = format!("src/{}", module.name.to_lowercase());
                    let module_path = module.root_path.as_deref().unwrap_or(&default_path);
                    if normalized_file_path.contains(&module_path.to_lowercase()) {
                        return true;
                    }
                }
            }
        }

        // 3. åŸºäºæ–‡ä»¶ååŒ¹é…ï¼ˆç®€å•å¯å‘å¼ï¼‰
        let file_name = Path::new(normalized_file_path)
            .file_name()
            .and_then(|n| n.to_str())
            .unwrap_or("");
        let task_name_lower = task.name.to_lowercase();

        // å¦‚æœæ–‡ä»¶ååŒ…å«ä»»åŠ¡åçš„ä¸€éƒ¨åˆ†ï¼Œå¯èƒ½ç›¸å…³
        let file_base_name = file_name
            .trim_end_matches(".ts")
            .trim_end_matches(".tsx")
            .trim_end_matches(".js")
            .trim_end_matches(".jsx")
            .trim_end_matches(".rs");

        if task_name_lower.contains(file_base_name)
            || file_base_name.contains(&task_name_lower.replace(' ', "-"))
        {
            return true;
        }

        false
    }

    /// æ‰§è¡Œæµ‹è¯•å‘½ä»¤
    async fn execute_test_command(
        config: &AcceptanceTestRunnerConfig,
        command: &str,
        test_file_path: Option<&str>,
    ) -> Result<String, String> {
        // æ„å»ºå®Œæ•´å‘½ä»¤
        let full_command = if let Some(path) = test_file_path {
            if !command.contains(path) {
                format!("{} {}", command, path)
            } else {
                command.to_string()
            }
        } else {
            command.to_string()
        };

        if config.debug {
            println!("[AcceptanceTestRunner] æ‰§è¡Œå‘½ä»¤: {}", full_command);
        }

        let parts: Vec<&str> = full_command.split_whitespace().collect();
        if parts.is_empty() {
            return Err("ç©ºå‘½ä»¤".to_string());
        }

        let cmd = parts[0];
        let args = &parts[1..];

        let output = Command::new(cmd)
            .args(args)
            .current_dir(&config.project_root)
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .output()
            .await
            .map_err(|e| format!("æ‰§è¡Œå‘½ä»¤å¤±è´¥: {}", e))?;

        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        let combined = format!("{}{}", stdout, stderr);

        if output.status.success() {
            Ok(combined)
        } else {
            Err(format!(
                "æµ‹è¯•å‘½ä»¤é€€å‡ºç : {:?}\n{}",
                output.status.code(),
                combined
            ))
        }
    }

    /// è§£ææµ‹è¯•æ˜¯å¦æˆåŠŸ
    fn parse_test_success(output: &str) -> bool {
        // vitest æˆåŠŸæ ‡è¯†
        if output.contains("Test Files") && output.contains("passed") {
            return !output.contains("failed");
        }

        // jest æˆåŠŸæ ‡è¯†
        if output.contains("Tests:") && output.contains("passed") {
            return !output.contains("failed");
        }

        // mocha æˆåŠŸæ ‡è¯†
        if output.contains("passing") {
            return !output.contains("failing");
        }

        // pytest æˆåŠŸæ ‡è¯†
        if output.contains("passed") || output.contains("PASSED") {
            return !output.contains("failed") && !output.contains("FAILED");
        }

        // cargo test æˆåŠŸæ ‡è¯†
        if output.contains("test result: ok") {
            return true;
        }
        if output.contains("test result: FAILED") {
            return false;
        }

        // é»˜è®¤ï¼šå‡è®¾æˆåŠŸï¼ˆå› ä¸ºæ²¡æœ‰å¼‚å¸¸é€€å‡ºï¼‰
        true
    }

    /// æå–é”™è¯¯ä¿¡æ¯
    fn extract_error_message(output: &str) -> String {
        let mut error_lines = Vec::new();
        let mut in_error = false;

        for line in output.lines() {
            if line.contains("Error:")
                || line.contains("FAIL")
                || line.contains("âœ–")
                || line.contains("AssertionError")
                || line.contains("panicked")
            {
                in_error = true;
            }

            if in_error {
                error_lines.push(line);
                if error_lines.len() >= 15 {
                    break;
                }
            }
        }

        if !error_lines.is_empty() {
            error_lines.join("\n")
        } else {
            output.chars().take(500).collect()
        }
    }

    /// è®°å½•æµ‹è¯•ç»“æœåˆ°ä»»åŠ¡æ ‘
    async fn record_results(&self, _tree_id: &str, results: &[AcceptanceTestRunResult]) {
        // æ³¨æ„ï¼šTaskTreeManager ç›®å‰æ²¡æœ‰ record_acceptance_test_result æ–¹æ³•
        // è¿™é‡Œåªæ‰“å°æ—¥å¿—ï¼Œå®é™…è®°å½•é€»è¾‘éœ€è¦åœ¨ TaskTreeManager ä¸­å®ç°
        for result in results {
            if result.passed {
                tracing::info!("éªŒæ”¶æµ‹è¯•é€šè¿‡: {} ({}ms)", result.test_name, result.duration);
            } else {
                tracing::warn!(
                    "éªŒæ”¶æµ‹è¯•å¤±è´¥: {} - {:?}",
                    result.test_name,
                    result.error_message
                );
            }
        }
    }

    /// ä»ä»»åŠ¡æ ‘ä¸­æ‰¾åˆ°æµ‹è¯•å¯¹åº”çš„ä»»åŠ¡ ID
    #[allow(dead_code)]
    fn find_task_id_for_test(root_task: &TaskNode, test_id: &str) -> Option<String> {
        for test in &root_task.acceptance_tests {
            if test.id == test_id {
                return Some(root_task.id.clone());
            }
        }

        for child in &root_task.children {
            if let Some(found) = Self::find_task_id_for_test(child, test_id) {
                return Some(found);
            }
        }

        None
    }

    /// æ‰“å°æ±‡æ€»
    fn print_summary(&self, results: &[AcceptanceTestRunResult]) {
        if results.is_empty() {
            return;
        }

        let passed = results.iter().filter(|r| r.passed).count();
        let failed = results.len() - passed;
        let total_duration: u64 = results.iter().map(|r| r.duration).sum();

        println!("\nğŸ“Š éªŒæ”¶æµ‹è¯•æ±‡æ€»:");
        println!(
            "   é€šè¿‡: {}, å¤±è´¥: {}, æ€»è€—æ—¶: {}ms",
            passed, failed, total_duration
        );

        if failed > 0 {
            println!("\nâš ï¸ å¤±è´¥çš„æµ‹è¯•:");
            for result in results.iter().filter(|r| !r.passed) {
                println!("   - {}", result.test_name);
            }
        }
    }

    /// åˆ›å»ºæ‰¹æ¬¡ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰
    fn create_batches<T: Clone>(&self, items: &[T], batch_size: usize) -> Vec<Vec<T>> {
        items.chunks(batch_size).map(|c| c.to_vec()).collect()
    }

    /// æ—¥å¿—è¾“å‡º
    fn log(&self, message: &str) {
        if self.config.debug {
            println!("{}", message);
        }
    }

    // --------------------------------------------------------------------------
    // é…ç½®ç®¡ç†
    // --------------------------------------------------------------------------

    /// è®¾ç½®é¡¹ç›®æ ¹ç›®å½•
    pub fn set_project_root(&mut self, project_root: PathBuf) {
        self.config.project_root = project_root;
    }

    /// è®¾ç½®æµ‹è¯•è¶…æ—¶æ—¶é—´
    pub fn set_test_timeout(&mut self, timeout: u64) {
        self.config.test_timeout = timeout;
    }

    /// è®¾ç½®è°ƒè¯•æ¨¡å¼
    pub fn set_debug(&mut self, debug: bool) {
        self.config.debug = debug;
    }
}

// ============================================================================
// å·¥å‚å‡½æ•°
// ============================================================================

/// åˆ›å»ºéªŒæ”¶æµ‹è¯•è¿è¡Œå™¨å®ä¾‹
pub fn create_acceptance_test_runner(
    config: AcceptanceTestRunnerConfig,
    task_tree_manager: Arc<RwLock<TaskTreeManager>>,
    blueprint_manager: Arc<RwLock<BlueprintManager>>,
) -> AcceptanceTestRunner {
    AcceptanceTestRunner::new(config, task_tree_manager, blueprint_manager)
}
